# Vision Agent ğŸ¬ğŸ§ 

![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)
![Python 3.11](https://img.shields.io/badge/Python-3.11-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688.svg)
![Docker](https://img.shields.io/badge/Docker-ready-2496ED.svg)
![YOLO](https://img.shields.io/badge/YOLOv8-detection-orange.svg)
![Gemini](https://img.shields.io/badge/Gemini-AI-4285F4.svg)

**Real-time multimodal AI video agent** â€” watches, listens, detects, and reasons about video in real-time with bounding box overlays and 2-tier agent intelligence.

> Stream live video â†’ YOLOv8 detects objects with bounding boxes â†’ Agent gives instant deterministic reply (<500ms) + polished LLM reply with provenance â†’ All measured and displayed in real-time.

Built for the [WeMakeDevs Vision Possible Hackathon](https://wemakedevs.org) â€” powered by [Vision Agents SDK](https://getstream.io/video/vision-agents/).

---

## âœ¨ Features

| Feature | Detail |
|---|---|
| ğŸ“¡ **Live Webcam Stream** | 2s chunk streaming with real-time YOLO detection + bounding box canvas overlays |
| ğŸ¯ **Bounding Box Overlays** | Canvas-drawn bboxes with labels, confidence %, and per-label color coding |
| ğŸ“Š **Real-Time Metrics** | 6-metric dashboard: chunks, avg latency, P90, model FPS, frames, objects |
| ğŸ¤– **2-Tier Agent** | FastReply (<500ms, deterministic) + PolishReply (LLM, ~3-8s, background) |
| ğŸ”— **Provenance Links** | Every agent response cites its sources: detection data, transcript, notes |
| ğŸ“¤ **Video Upload** | Drag-and-drop MP4/MOV/WebM, full pipeline analysis |
| ğŸ™ï¸ **Audio Transcription** | OpenAI Whisper API (cloud) |
| ğŸ” **Object Detection** | YOLOv8n per-frame with full `[x1,y1,x2,y2]` bounding boxes |
| ğŸ§  **AI Notes** | LLM-generated summary, concepts, formulas, viva questions |
| ğŸ’¬ **Click-to-Ask** | Click a detected label â†’ agent answers with context |
| ğŸ§ª **Quiz Generator** | MCQs + short-answer questions with auto-scoring |
| âš¡ **Dual LLM** | Gemini + OpenAI with auto-fallback + quota handling |
| ğŸŒ **URL Ingestion** | Paste YouTube/Vimeo URL â†’ auto-download + full analysis |
| ğŸ“ **LaTeX Formulas** | MathJax-rendered formulas from lectures |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser UI  â”‚â”€â”€â”€â–¶â”‚                FastAPI Server                     â”‚
â”‚              â”‚    â”‚                                                   â”‚
â”‚  ğŸ¥ Live     â”‚    â”‚  /stream_chunk â”€â”€â–¶ vision_worker.py (YOLO)       â”‚
â”‚  Stream +    â”‚    â”‚                    â†³ bboxes + latency tracking    â”‚
â”‚  Canvas      â”‚    â”‚  /stream_status â”€â”€â–¶ real-time metrics            â”‚
â”‚  Overlays    â”‚    â”‚                                                   â”‚
â”‚              â”‚    â”‚  /ask â”€â”€â–¶ agent_core.py                           â”‚
â”‚  ğŸ“Š Metrics  â”‚    â”‚           â”œâ”€ Tier A: FastReply (<500ms)           â”‚
â”‚  Dashboard   â”‚    â”‚           â””â”€ Tier B: PolishReply (LLM + jobs.py) â”‚
â”‚              â”‚    â”‚                                                   â”‚
â”‚  ğŸ¤– Agent    â”‚    â”‚  /analyze â”€â”€â–¶ ffmpeg â”€â”€â–¶ whisper â”€â”€â–¶ YOLO        â”‚
â”‚  Chat Panel  â”‚    â”‚  /generate_notes â”€â”€â–¶ llm_provider.py (async job) â”‚
â”‚              â”‚    â”‚  /ingest_url â”€â”€â–¶ yt-dlp â”€â”€â–¶ full pipeline        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2-Tier Agent Intelligence

```
User clicks "person" label
         â”‚
         â–¼
â”Œâ”€ Tier A: FastReply â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Template + YOLO labels + transcript â”‚  < 500ms
â”‚ "I see person Ã—3 in the video"   â”‚  deterministic
â”‚ Source: detection, transcript    â”‚  cached
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ (background LLM job)
â”Œâ”€ Tier B: PolishReply â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Full context â†’ Gemini/OpenAI     â”‚  ~3-8s
â”‚ Detailed analysis with reasoning â”‚  provenance links
â”‚ Auto-fallback on quota/timeout   â”‚  polls /jobs/{id}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Option A: Docker (recommended)

```bash
OPENAI_API_KEY="sk-..." GEMINI_API_KEY="..." docker compose up --build
# Open http://localhost:8000
```

### Option B: Local Setup

#### Prerequisites
- **Python 3.10+**
- **ffmpeg** on PATH ([download](https://ffmpeg.org/download.html))
- **API key**: OpenAI and/or Gemini

#### Windows PowerShell

```powershell
cd vision-agent\backend
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
$env:OPENAI_API_KEY = "sk-..."
$env:GEMINI_API_KEY = "..."
uvicorn main:app --reload --port 8000
```

#### Linux / macOS

```bash
cd vision-agent/backend
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
export OPENAI_API_KEY="sk-..." GEMINI_API_KEY="..."
uvicorn main:app --reload --port 8000
```

> **ğŸ’¡ No API key?** Server runs fine â€” transcription returns placeholder, notes use pre-generated samples. Judges can see the full UI and stream demo immediately.

## ğŸ“¡ API Endpoints

| Method | Path | Description |
|---|---|---|
| GET | `/` | Upload & live-stream UI |
| GET | `/demo` | Interactive demo (QA, quiz, timeline) |
| POST | `/upload` | Upload video â†’ extract frames |
| POST | `/analyze` | Full pipeline: frames + transcript + detection |
| POST | `/generate_notes` | Async LLM notes generation (returns job_id) |
| POST | `/ask` | **2-tier agent**: fast reply + background LLM polish |
| POST | `/generate_quiz` | MCQ + short-answer quiz |
| POST | `/stream_chunk` | Stream 2s chunk â†’ YOLO bboxes + transcript |
| GET | `/stream_status` | Real-time metrics: latency, FPS, detections |
| POST | `/stream_finalize` | Stitch chunks + full analysis |
| POST | `/ingest_url` | Download from URL + full pipeline |
| GET | `/jobs/{id}` | Poll async job progress |

## âš™ï¸ Environment Variables

| Variable | Default | Description |
|---|---|---|
| `OPENAI_API_KEY` | â€” | Transcription (Whisper), notes, QA, quiz |
| `GEMINI_API_KEY` | â€” | Gemini LLM for notes + agent reasoning |
| `LLM_PROVIDER` | `auto` | `gemini`, `openai`, or `auto` (try both) |
| `CLOUDFLARE_ACCOUNT_ID` | â€” | Cloudflare Workers AI account id (optional) |
| `CLOUDFLARE_API_TOKEN` | â€” | Cloudflare Workers AI API token (optional) |
| `CLOUDFLARE_MODEL` | `@cf/qwen/qwen1.5-14b-chat-awq` | Cloudflare Workers AI model id |
| `GEMINI_MODEL` | `gemini-2.0-flash` | Gemini model |
| `OPENAI_MODEL` | `gpt-4o-mini` | OpenAI chat model |
| `YOLO_MODEL` | `yolov8n.pt` | YOLO model file (nano/small/medium) |

### Live Coach (Pose + Rep Counting)

The Live Stream tab now includes a **fitness coach panel** (exercise selection, rep counter, form cues, and optional browser voice feedback).

- **Backend dependency**: `mediapipe` (installed via `backend/requirements.txt`). If it is missing, the rest of the app still works, but rep counting will be disabled.
- **No paid TTS required**: the UI uses the browser's built-in Speech Synthesis when enabled.

## ğŸ› ï¸ Tech Stack

- **Backend**: Python 3.11, FastAPI, Uvicorn
- **Vision**: YOLOv8 (ultralytics), OpenCV, `vision_worker.py` singleton
- **Audio**: OpenAI Whisper API
- **LLM**: Gemini + OpenAI with provider abstraction (`llm_provider.py`)
- **Agent**: 2-tier reasoning engine (`agent_core.py`)
- **Jobs**: Thread-safe async job store (`jobs.py`)
- **Math**: MathJax 3 (LaTeX rendering)
- **Streaming**: ffmpeg, MediaRecorder API, growing-file WebM strategy
- **Frontend**: Vanilla HTML/CSS/JS, Canvas API for bounding boxes, dark glassmorphism
- **Deploy**: Docker, GitHub Actions CI

## ğŸ“ Project Structure

```
vision-agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app (all routes)
â”‚   â”œâ”€â”€ agent_core.py        # 2-tier agent: FastReply + PolishReply
â”‚   â”œâ”€â”€ vision_worker.py     # Singleton YOLO worker with latency tracking
â”‚   â”œâ”€â”€ detect.py            # YOLOv8 detection with bounding boxes
â”‚   â”œâ”€â”€ frame_extractor.py   # OpenCV frame extraction
â”‚   â”œâ”€â”€ transcribe.py        # OpenAI Whisper transcription
â”‚   â”œâ”€â”€ llm_provider.py      # Gemini/OpenAI provider abstraction
â”‚   â”œâ”€â”€ jobs.py              # Thread-safe async job store
â”‚   â”œâ”€â”€ streaming.py         # Real-time chunk streaming + /stream_status
â”‚   â”œâ”€â”€ url_ingest.py        # URL download + pipeline
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ analysis/sample/     # Pre-generated outputs for judges
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ index.html       # Upload & live-stream UI with canvas overlays
â”‚       â””â”€â”€ demo.html        # Interactive demo (QA, quiz, timeline)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ SUBMISSION_NOTES.md
â”œâ”€â”€ BLOG_POST.md
â””â”€â”€ LICENSE
```

## ğŸ“Š Performance Metrics

| Step | Time | Notes |
|---|---|---|
| Frame extraction (30s video) | ~1-2s | OpenCV at 1 fps |
| Whisper transcription (cloud) | ~2-5s | Depends on audio length |
| YOLOv8 detection (30 frames) | ~3-6s | Nano model, CPU |
| LLM notes generation | ~3-8s | Gemini 2.0 Flash or GPT-4o-mini |
| FastReply (agent Tier A) | **<500ms** | Deterministic, cached |
| PolishReply (agent Tier B) | ~3-8s | Full LLM analysis |
| Stream chunk (end-to-end) | ~2-5s | Transcode + extract + detect |
| **Total pipeline** | **~10-20s** | Full upload â†’ analysis |

## License

MIT â€” see [LICENSE](LICENSE)

---

Built with â¤ï¸ for the **WeMakeDevs Vision Possible Hackathon** â€” powered by [Vision Agents SDK](https://getstream.io/video/vision-agents/), [Gemini](https://ai.google.dev/), & [OpenAI](https://openai.com)
